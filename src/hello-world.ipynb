{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Langchain using Open AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import OpenAI \n",
    "- First install Open AI using `pip install openai`\n",
    "- install env utilities `pip install python-dotenv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import datetime\n",
    "# Load local env file\n",
    "_ = load_dotenv(find_dotenv())\n",
    "# Read openai api key from local environment\n",
    "llm_model = 'gpt-3.5-turbo'\n",
    "temperature=0.2\n",
    "open_ai = OpenAI(\n",
    "  organization='org-ipcibHwhY3NFYtBdJIvODK7m',\n",
    "  api_key=os.environ['OPENAI_API_KEY'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open AI without Langchain\n",
    "- Without langchain following block is how open ai calls are made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I hate my class, the kids are so annoying!"
     ]
    }
   ],
   "source": [
    "# define functiont to complete\n",
    "def get_completion_gpt(prompt,model=llm_model):\n",
    "    messages = [{\"role\":\"user\",\"content\":prompt}]\n",
    "    response = open_ai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        stream=True,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "# test with a prompt\n",
    "user_msg = \"I do not like my class, the kids are unruly !\"\n",
    "style = \"English in informal Gen Alpha persona\"\n",
    "prompt = f\"\"\"Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{user_msg}```\"\"\"\n",
    "\n",
    "response = get_completion_gpt(prompt)\n",
    "for chunk in response:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open AI with LangChain\n",
    "- Install Langchain first \n",
    "- Use LangSmith for Observability [Official Document](https://python.langchain.com/docs/tutorials/llm_chain/)\n",
    "- Signup for LangSmith API key [How To...](https://smith.langchain.com/onboarding?organizationId=a1b11d3c-e3c3-4439-9ebc-a077a7c0de67&step=1)\n",
    "- Trace via LangSmith [Link](https://smith.langchain.com/o/a1b11d3c-e3c3-4439-9ebc-a077a7c0de67/projects/p/9deedd89-2b39-4469-afaa-fe78f12f0bf2?timeModel=%7B%22duration%22%3A%227d%22%7D&tab=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ugh, my class is the worst! The kids are so out of control!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install -U langchain langchain-openai\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=llm_model)\n",
    "\n",
    "# import system prompt and user prompt from langchain\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=f\"\"\"Translate the following text into a persona that is {style}\"\"\"),\n",
    "    HumanMessage(content=user_msg)\n",
    "]\n",
    "\n",
    "# import langchain parser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# parser.invoke(llm.invoke(messages))\n",
    "# More modern way of invoking the response and parsing is by using |\n",
    "chain = llm | parser\n",
    "chain.invoke(messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
